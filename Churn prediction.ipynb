{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement: Use ANN model to predict if the customer will leave the bank**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  int64  \n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RowNumber</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>2886.895680</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2500.75</td>\n",
       "      <td>5.000500e+03</td>\n",
       "      <td>7.500250e+03</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>71936.186123</td>\n",
       "      <td>15565701.00</td>\n",
       "      <td>15628528.25</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>15815690.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>6.505288e+02</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>350.00</td>\n",
       "      <td>584.00</td>\n",
       "      <td>6.520000e+02</td>\n",
       "      <td>7.180000e+02</td>\n",
       "      <td>850.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>3.892180e+01</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>92.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.012800e+00</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.648589e+04</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.719854e+04</td>\n",
       "      <td>1.276442e+05</td>\n",
       "      <td>250898.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.530200e+00</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>7.055000e-01</td>\n",
       "      <td>0.455840</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>5.151000e-01</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.000902e+05</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>11.58</td>\n",
       "      <td>51002.11</td>\n",
       "      <td>1.001939e+05</td>\n",
       "      <td>1.493882e+05</td>\n",
       "      <td>199992.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exited</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2.037000e-01</td>\n",
       "      <td>0.402769</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count          mean           std          min  \\\n",
       "RowNumber        10000.0  5.000500e+03   2886.895680         1.00   \n",
       "CustomerId       10000.0  1.569094e+07  71936.186123  15565701.00   \n",
       "CreditScore      10000.0  6.505288e+02     96.653299       350.00   \n",
       "Age              10000.0  3.892180e+01     10.487806        18.00   \n",
       "Tenure           10000.0  5.012800e+00      2.892174         0.00   \n",
       "Balance          10000.0  7.648589e+04  62397.405202         0.00   \n",
       "NumOfProducts    10000.0  1.530200e+00      0.581654         1.00   \n",
       "HasCrCard        10000.0  7.055000e-01      0.455840         0.00   \n",
       "IsActiveMember   10000.0  5.151000e-01      0.499797         0.00   \n",
       "EstimatedSalary  10000.0  1.000902e+05  57510.492818        11.58   \n",
       "Exited           10000.0  2.037000e-01      0.402769         0.00   \n",
       "\n",
       "                         25%           50%           75%          max  \n",
       "RowNumber            2500.75  5.000500e+03  7.500250e+03     10000.00  \n",
       "CustomerId       15628528.25  1.569074e+07  1.575323e+07  15815690.00  \n",
       "CreditScore           584.00  6.520000e+02  7.180000e+02       850.00  \n",
       "Age                    32.00  3.700000e+01  4.400000e+01        92.00  \n",
       "Tenure                  3.00  5.000000e+00  7.000000e+00        10.00  \n",
       "Balance                 0.00  9.719854e+04  1.276442e+05    250898.09  \n",
       "NumOfProducts           1.00  1.000000e+00  2.000000e+00         4.00  \n",
       "HasCrCard               0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "IsActiveMember          0.00  1.000000e+00  1.000000e+00         1.00  \n",
       "EstimatedSalary     51002.11  1.001939e+05  1.493882e+05    199992.48  \n",
       "Exited                  0.00  0.000000e+00  0.000000e+00         1.00  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Exited', ylabel='count'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Exited',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1b9933df580>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(data=df,x='Exited',col='Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['RowNumber','CustomerId','Surname'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Geography', 'Gender'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "objList = df.select_dtypes(include = \"object\").columns\n",
    "print (objList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  int32  \n",
      " 2   Gender           10000 non-null  int32  \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int32(2), int64(7)\n",
      "memory usage: 781.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for feature in objList:\n",
    "    df[feature] = le.fit_transform(df[feature].astype(str))\n",
    "\n",
    "print (df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          0       0   42       2       0.00              1   \n",
       "1             608          2       0   41       1   83807.86              1   \n",
       "2             502          0       0   42       8  159660.80              3   \n",
       "3             699          0       0   39       1       0.00              2   \n",
       "4             850          2       0   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          0       1   39       5       0.00              2   \n",
       "9996          516          0       1   35      10   57369.61              1   \n",
       "9997          709          0       0   36       7       0.00              1   \n",
       "9998          772          1       1   42       3   75075.31              2   \n",
       "9999          792          0       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0             1               1        101348.88       1  \n",
       "1             0               1        112542.58       0  \n",
       "2             1               0        113931.57       1  \n",
       "3             0               0         93826.63       0  \n",
       "4             1               1         79084.10       0  \n",
       "...         ...             ...              ...     ...  \n",
       "9995          1               0         96270.64       0  \n",
       "9996          1               1        101699.77       0  \n",
       "9997          0               1         42085.58       1  \n",
       "9998          1               0         92888.52       1  \n",
       "9999          1               0         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited',axis=1).values\n",
    "y = df['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(units=12,activation='relu'))  #input\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))  #hidden\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))   #output\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.5762 - val_loss: 0.4997\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4935 - val_loss: 0.4808\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4925 - val_loss: 0.4655\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4659 - val_loss: 0.4536\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.4454\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4483 - val_loss: 0.4336\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4405 - val_loss: 0.4285\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4345 - val_loss: 0.4232\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4277 - val_loss: 0.4127\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4007 - val_loss: 0.4005\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4001 - val_loss: 0.3928\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.3873\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3902 - val_loss: 0.3854\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.3826\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.3779\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3842 - val_loss: 0.3761\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.3754\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3763 - val_loss: 0.3780\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3836 - val_loss: 0.3711\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3618 - val_loss: 0.3712\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.3676\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.3664\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.3663\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.3684\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.3639\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3501 - val_loss: 0.3635\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3630\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.3646\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.3622\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3545 - val_loss: 0.3624\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.3609\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.3620\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3586 - val_loss: 0.3614\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.3598\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.3597\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3470 - val_loss: 0.3597\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.3687\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.3583\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.3611\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3534 - val_loss: 0.3593\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3518 - val_loss: 0.3581\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.3580\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3506 - val_loss: 0.3576\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.3650\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3555 - val_loss: 0.3592\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.3628\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.3578\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.3573\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3415 - val_loss: 0.3560\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3554\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.3622\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.3622\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.3597\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.3556\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3570\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3322 - val_loss: 0.3559\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3335 - val_loss: 0.3617\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3449 - val_loss: 0.3545\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3589\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3547 - val_loss: 0.3539\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.3561\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3427 - val_loss: 0.3567\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3362 - val_loss: 0.3558\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.3540\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3538 - val_loss: 0.3532\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3433 - val_loss: 0.3546\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.3535\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3522 - val_loss: 0.3529\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3433 - val_loss: 0.3631\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3376 - val_loss: 0.3546\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.346 - 1s 4ms/step - loss: 0.3462 - val_loss: 0.3534\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3530\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3249 - val_loss: 0.3602\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3389 - val_loss: 0.3600\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3401 - val_loss: 0.3530\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3380 - val_loss: 0.3532\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.3525\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3527\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.3604\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.3575\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3558\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3527\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3546\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3267 - val_loss: 0.3526\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.3520\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.3526\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3515 - val_loss: 0.3516\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3650\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3523\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3513\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3374 - val_loss: 0.3505\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3521\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3255 - val_loss: 0.3510\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3532\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3549\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3349 - val_loss: 0.3514\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3313 - val_loss: 0.3497\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3401 - val_loss: 0.3545\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3522\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3509\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.3494\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3534\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3496\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3506\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3515\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3388 - val_loss: 0.3517\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3313 - val_loss: 0.3477\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3499\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3483\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3229 - val_loss: 0.3605\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3503\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3238 - val_loss: 0.3476\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3525\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3481\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3478\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3192 - val_loss: 0.3504\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3311 - val_loss: 0.3515\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3496\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3287 - val_loss: 0.3470\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3251 - val_loss: 0.3484\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3378 - val_loss: 0.3468\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3337 - val_loss: 0.3509\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3225 - val_loss: 0.3548\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - val_loss: 0.3477\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - val_loss: 0.3495\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3511\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3303 - val_loss: 0.3491\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - val_loss: 0.3521\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3494\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3474\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3400 - val_loss: 0.3481\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3351 - val_loss: 0.3483\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - val_loss: 0.3474\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - val_loss: 0.3493\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3542\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3228 - val_loss: 0.3461\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3480\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3341 - val_loss: 0.3519\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3482\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3470\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - val_loss: 0.3468\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3490\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3506\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3347 - val_loss: 0.3459\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3465\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3327 - val_loss: 0.3470\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3425 - val_loss: 0.3457\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - val_loss: 0.3457\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3282 - val_loss: 0.3460\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3338 - val_loss: 0.3451\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3198 - val_loss: 0.3476\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3457\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3295 - val_loss: 0.3479\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3457\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3455\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3447\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - val_loss: 0.3448\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3455\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - val_loss: 0.3499\n",
      "Epoch 160/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3149 - val_loss: 0.3448\n",
      "Epoch 162/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.3519\n",
      "Epoch 163/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3448\n",
      "Epoch 164/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3469\n",
      "Epoch 165/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3452\n",
      "Epoch 166/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3128 - val_loss: 0.3451\n",
      "Epoch 167/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3461\n",
      "Epoch 168/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3459\n",
      "Epoch 169/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3483\n",
      "Epoch 170/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - val_loss: 0.3516\n",
      "Epoch 171/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3455\n",
      "Epoch 172/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3320 - val_loss: 0.3541\n",
      "Epoch 173/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3254 - val_loss: 0.3448\n",
      "Epoch 174/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.3475\n",
      "Epoch 175/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3159 - val_loss: 0.3442\n",
      "Epoch 176/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3447\n",
      "Epoch 177/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3252 - val_loss: 0.3446\n",
      "Epoch 178/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3375 - val_loss: 0.3445\n",
      "Epoch 179/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3251 - val_loss: 0.3448\n",
      "Epoch 180/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.3503\n",
      "Epoch 181/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3278 - val_loss: 0.3431\n",
      "Epoch 182/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3175 - val_loss: 0.3456\n",
      "Epoch 183/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3164 - val_loss: 0.3524\n",
      "Epoch 184/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3234 - val_loss: 0.3455\n",
      "Epoch 185/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3219 - val_loss: 0.3432\n",
      "Epoch 186/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.324 - 1s 2ms/step - loss: 0.3249 - val_loss: 0.3446\n",
      "Epoch 187/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3432\n",
      "Epoch 188/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - val_loss: 0.3442\n",
      "Epoch 189/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3455\n",
      "Epoch 190/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3308 - val_loss: 0.3443\n",
      "Epoch 191/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3451\n",
      "Epoch 192/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3281 - val_loss: 0.3444\n",
      "Epoch 193/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3334 - val_loss: 0.3459\n",
      "Epoch 194/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3456\n",
      "Epoch 195/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3605\n",
      "Epoch 196/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3243 - val_loss: 0.3437\n",
      "Epoch 197/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3439\n",
      "Epoch 198/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3260 - val_loss: 0.3430\n",
      "Epoch 199/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3443\n",
      "Epoch 200/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - val_loss: 0.3448\n",
      "Epoch 201/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3468\n",
      "Epoch 202/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3277 - val_loss: 0.3609\n",
      "Epoch 203/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3433\n",
      "Epoch 204/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3248 - val_loss: 0.3441\n",
      "Epoch 205/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3464\n",
      "Epoch 206/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3201 - val_loss: 0.3437\n",
      "Epoch 207/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3234 - val_loss: 0.3429\n",
      "Epoch 208/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3433\n",
      "Epoch 209/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3281 - val_loss: 0.3426\n",
      "Epoch 210/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3202 - val_loss: 0.3439\n",
      "Epoch 211/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3442\n",
      "Epoch 212/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3451\n",
      "Epoch 213/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3109 - val_loss: 0.3521\n",
      "Epoch 214/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3448\n",
      "Epoch 215/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3386 - val_loss: 0.3431\n",
      "Epoch 216/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.3549\n",
      "Epoch 217/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3454\n",
      "Epoch 218/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3454\n",
      "Epoch 219/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3492\n",
      "Epoch 220/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3263 - val_loss: 0.3452\n",
      "Epoch 221/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3161 - val_loss: 0.3471\n",
      "Epoch 222/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3428\n",
      "Epoch 223/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3252 - val_loss: 0.3444\n",
      "Epoch 224/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3446\n",
      "Epoch 225/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3447\n",
      "Epoch 226/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3302 - val_loss: 0.3469\n",
      "Epoch 227/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3134 - val_loss: 0.3431\n",
      "Epoch 228/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3435\n",
      "Epoch 229/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3427\n",
      "Epoch 230/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3432\n",
      "Epoch 231/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3427\n",
      "Epoch 232/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3158 - val_loss: 0.3478\n",
      "Epoch 233/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3221 - val_loss: 0.3442\n",
      "Epoch 234/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3114 - val_loss: 0.3433\n",
      "Epoch 235/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3295 - val_loss: 0.3447\n",
      "Epoch 236/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3501\n",
      "Epoch 237/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3163 - val_loss: 0.3420\n",
      "Epoch 238/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3426\n",
      "Epoch 239/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3435\n",
      "Epoch 240/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3167 - val_loss: 0.3470\n",
      "Epoch 241/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3439\n",
      "Epoch 242/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3213 - val_loss: 0.3445\n",
      "Epoch 243/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3173 - val_loss: 0.3446\n",
      "Epoch 244/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3156 - val_loss: 0.3473\n",
      "Epoch 245/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3202 - val_loss: 0.3476\n",
      "Epoch 246/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.3441\n",
      "Epoch 247/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3426\n",
      "Epoch 248/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3425\n",
      "Epoch 249/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3198 - val_loss: 0.3438\n",
      "Epoch 250/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3439\n",
      "Epoch 251/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3445\n",
      "Epoch 252/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3448\n",
      "Epoch 253/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3454\n",
      "Epoch 254/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3442\n",
      "Epoch 255/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.3431\n",
      "Epoch 256/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3176 - val_loss: 0.3436\n",
      "Epoch 257/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3079 - val_loss: 0.3474\n",
      "Epoch 258/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3195 - val_loss: 0.3435\n",
      "Epoch 259/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3459\n",
      "Epoch 260/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3043 - val_loss: 0.3441\n",
      "Epoch 261/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3246 - val_loss: 0.3425\n",
      "Epoch 262/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3434\n",
      "Epoch 263/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3448\n",
      "Epoch 264/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3461\n",
      "Epoch 265/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3305 - val_loss: 0.3435\n",
      "Epoch 266/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3431\n",
      "Epoch 267/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3465\n",
      "Epoch 268/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3554\n",
      "Epoch 269/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3471\n",
      "Epoch 270/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3225 - val_loss: 0.3491\n",
      "Epoch 271/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3495\n",
      "Epoch 272/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3104 - val_loss: 0.3434\n",
      "Epoch 273/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3153 - val_loss: 0.3489\n",
      "Epoch 274/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3284 - val_loss: 0.3469\n",
      "Epoch 275/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3266 - val_loss: 0.3432\n",
      "Epoch 276/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3417\n",
      "Epoch 277/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3430\n",
      "Epoch 278/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3429\n",
      "Epoch 279/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3176 - val_loss: 0.3440\n",
      "Epoch 280/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3103 - val_loss: 0.3437\n",
      "Epoch 281/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3294 - val_loss: 0.3455\n",
      "Epoch 282/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3438\n",
      "Epoch 283/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3150 - val_loss: 0.3443\n",
      "Epoch 284/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.3435\n",
      "Epoch 285/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3447\n",
      "Epoch 286/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.322 - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3455\n",
      "Epoch 287/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3425\n",
      "Epoch 288/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3242 - val_loss: 0.3426\n",
      "Epoch 289/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3175 - val_loss: 0.3427\n",
      "Epoch 290/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3384 - val_loss: 0.3481\n",
      "Epoch 291/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3434\n",
      "Epoch 292/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3164 - val_loss: 0.3637\n",
      "Epoch 293/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3252 - val_loss: 0.3425\n",
      "Epoch 294/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3235 - val_loss: 0.3450\n",
      "Epoch 295/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3468\n",
      "Epoch 296/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3299 - val_loss: 0.3437\n",
      "Epoch 297/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3444\n",
      "Epoch 298/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3181 - val_loss: 0.3448\n",
      "Epoch 299/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3167 - val_loss: 0.3454\n",
      "Epoch 300/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3451\n",
      "Epoch 301/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3254 - val_loss: 0.3599\n",
      "Epoch 302/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3321 - val_loss: 0.3428\n",
      "Epoch 303/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3435\n",
      "Epoch 304/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3220 - val_loss: 0.3458\n",
      "Epoch 305/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3437\n",
      "Epoch 306/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3444\n",
      "Epoch 307/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3214 - val_loss: 0.3479\n",
      "Epoch 308/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3267 - val_loss: 0.3446\n",
      "Epoch 309/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3273 - val_loss: 0.3422\n",
      "Epoch 310/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3189 - val_loss: 0.3438\n",
      "Epoch 311/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3438\n",
      "Epoch 312/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3457\n",
      "Epoch 313/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3156 - val_loss: 0.3435\n",
      "Epoch 314/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3530\n",
      "Epoch 315/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3165 - val_loss: 0.3438\n",
      "Epoch 316/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.3592\n",
      "Epoch 317/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3441\n",
      "Epoch 318/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3447\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3431\n",
      "Epoch 320/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3434\n",
      "Epoch 321/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3203 - val_loss: 0.3458\n",
      "Epoch 322/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3201 - val_loss: 0.3481\n",
      "Epoch 323/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3302 - val_loss: 0.3435\n",
      "Epoch 324/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3209 - val_loss: 0.3513\n",
      "Epoch 325/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3232 - val_loss: 0.3475\n",
      "Epoch 326/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3170 - val_loss: 0.3443\n",
      "Epoch 327/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3502\n",
      "Epoch 328/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3447\n",
      "Epoch 329/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3224 - val_loss: 0.3474\n",
      "Epoch 330/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3278 - val_loss: 0.3479\n",
      "Epoch 331/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.314 - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3420\n",
      "Epoch 332/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3454\n",
      "Epoch 333/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.3465\n",
      "Epoch 334/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3090 - val_loss: 0.3436\n",
      "Epoch 335/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3313 - val_loss: 0.3474\n",
      "Epoch 336/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3432\n",
      "Epoch 337/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3314 - val_loss: 0.3443\n",
      "Epoch 338/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3207 - val_loss: 0.3518\n",
      "Epoch 339/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3439\n",
      "Epoch 340/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3176 - val_loss: 0.3442\n",
      "Epoch 341/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3424\n",
      "Epoch 342/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3229 - val_loss: 0.3430\n",
      "Epoch 343/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3196 - val_loss: 0.3449\n",
      "Epoch 344/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3224 - val_loss: 0.3431\n",
      "Epoch 345/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3227 - val_loss: 0.3474\n",
      "Epoch 346/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3135 - val_loss: 0.3434\n",
      "Epoch 347/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3053 - val_loss: 0.3454\n",
      "Epoch 348/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3188 - val_loss: 0.3440\n",
      "Epoch 349/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3451\n",
      "Epoch 350/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3467\n",
      "Epoch 351/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3448\n",
      "Epoch 352/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3427\n",
      "Epoch 353/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3095 - val_loss: 0.3439\n",
      "Epoch 354/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.3473\n",
      "Epoch 355/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3179 - val_loss: 0.3423\n",
      "Epoch 356/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3030 - val_loss: 0.3511\n",
      "Epoch 357/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3089 - val_loss: 0.3527\n",
      "Epoch 358/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3135 - val_loss: 0.3447\n",
      "Epoch 359/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3132 - val_loss: 0.3487\n",
      "Epoch 360/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3163 - val_loss: 0.3424\n",
      "Epoch 361/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3469\n",
      "Epoch 362/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3430\n",
      "Epoch 363/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3219 - val_loss: 0.3429\n",
      "Epoch 364/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3237 - val_loss: 0.3469\n",
      "Epoch 365/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3448\n",
      "Epoch 366/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3138 - val_loss: 0.3432\n",
      "Epoch 367/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3158 - val_loss: 0.3465\n",
      "Epoch 368/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3227 - val_loss: 0.3498\n",
      "Epoch 369/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3453\n",
      "Epoch 370/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3266 - val_loss: 0.3437\n",
      "Epoch 371/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3429\n",
      "Epoch 372/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3215 - val_loss: 0.3433\n",
      "Epoch 373/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3247 - val_loss: 0.3442\n",
      "Epoch 374/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3211 - val_loss: 0.3452\n",
      "Epoch 375/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3258 - val_loss: 0.3498\n",
      "Epoch 376/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3455\n",
      "Epoch 377/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3432\n",
      "Epoch 378/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3458\n",
      "Epoch 379/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3147 - val_loss: 0.3583\n",
      "Epoch 380/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3255 - val_loss: 0.3426\n",
      "Epoch 381/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.3451\n",
      "Epoch 382/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3448\n",
      "Epoch 383/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3460\n",
      "Epoch 384/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3507\n",
      "Epoch 385/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3111 - val_loss: 0.3427\n",
      "Epoch 386/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3503\n",
      "Epoch 387/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3157 - val_loss: 0.3432\n",
      "Epoch 388/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3435\n",
      "Epoch 389/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3206 - val_loss: 0.3473\n",
      "Epoch 390/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3174 - val_loss: 0.3420\n",
      "Epoch 391/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3172 - val_loss: 0.3434\n",
      "Epoch 392/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3415\n",
      "Epoch 393/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3445\n",
      "Epoch 394/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3105 - val_loss: 0.3429\n",
      "Epoch 395/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.3431\n",
      "Epoch 396/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3336 - val_loss: 0.3455\n",
      "Epoch 397/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3196 - val_loss: 0.3461\n",
      "Epoch 398/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3168 - val_loss: 0.3447\n",
      "Epoch 399/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3138 - val_loss: 0.3495\n",
      "Epoch 400/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3193 - val_loss: 0.3434\n",
      "Epoch 401/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3114 - val_loss: 0.3433\n",
      "Epoch 402/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3498\n",
      "Epoch 403/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3255 - val_loss: 0.3461\n",
      "Epoch 404/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3236 - val_loss: 0.3459\n",
      "Epoch 405/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3054 - val_loss: 0.3438\n",
      "Epoch 406/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3482\n",
      "Epoch 407/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3297 - val_loss: 0.3444\n",
      "Epoch 408/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3508\n",
      "Epoch 409/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3160 - val_loss: 0.3441\n",
      "Epoch 410/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3199 - val_loss: 0.3441\n",
      "Epoch 411/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3445\n",
      "Epoch 412/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3599\n",
      "Epoch 413/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3432\n",
      "Epoch 414/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3264 - val_loss: 0.3413\n",
      "Epoch 415/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3432\n",
      "Epoch 416/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3442\n",
      "Epoch 417/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3197 - val_loss: 0.3467\n",
      "Epoch 418/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3162 - val_loss: 0.3451\n",
      "Epoch 419/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3160 - val_loss: 0.3439\n",
      "Epoch 420/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3191 - val_loss: 0.3469\n",
      "Epoch 421/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3220 - val_loss: 0.3433\n",
      "Epoch 422/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3216 - val_loss: 0.3460\n",
      "Epoch 423/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3203 - val_loss: 0.3430\n",
      "Epoch 424/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3042 - val_loss: 0.3504\n",
      "Epoch 425/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3469\n",
      "Epoch 426/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3217 - val_loss: 0.3536\n",
      "Epoch 427/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3118 - val_loss: 0.3431\n",
      "Epoch 428/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3123 - val_loss: 0.3452\n",
      "Epoch 429/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3251 - val_loss: 0.3459\n",
      "Epoch 430/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3164 - val_loss: 0.3482\n",
      "Epoch 431/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3194 - val_loss: 0.3472\n",
      "Epoch 432/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3440\n",
      "Epoch 433/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3467\n",
      "Epoch 434/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3439\n",
      "Epoch 435/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3105 - val_loss: 0.3487\n",
      "Epoch 436/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3446\n",
      "Epoch 437/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3139 - val_loss: 0.3421\n",
      "Epoch 438/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3450\n",
      "Epoch 439/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3429\n",
      "Epoch 440/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3466\n",
      "Epoch 441/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3134 - val_loss: 0.3454\n",
      "Epoch 442/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3430\n",
      "Epoch 443/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3172 - val_loss: 0.3440\n",
      "Epoch 444/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3148 - val_loss: 0.3459\n",
      "Epoch 445/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3163 - val_loss: 0.3499\n",
      "Epoch 446/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3169 - val_loss: 0.3426\n",
      "Epoch 447/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3431\n",
      "Epoch 448/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3229 - val_loss: 0.3439\n",
      "Epoch 449/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3200 - val_loss: 0.3428\n",
      "Epoch 450/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3125 - val_loss: 0.3421\n",
      "Epoch 451/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3133 - val_loss: 0.3443\n",
      "Epoch 452/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3274 - val_loss: 0.3454\n",
      "Epoch 453/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3470\n",
      "Epoch 454/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3501\n",
      "Epoch 455/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3194 - val_loss: 0.3435\n",
      "Epoch 456/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3245 - val_loss: 0.3434\n",
      "Epoch 457/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - val_loss: 0.3422\n",
      "Epoch 458/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3267 - val_loss: 0.3442\n",
      "Epoch 459/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3207 - val_loss: 0.3457\n",
      "Epoch 460/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3441\n",
      "Epoch 461/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3271 - val_loss: 0.3443\n",
      "Epoch 462/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3213 - val_loss: 0.3464\n",
      "Epoch 463/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3184 - val_loss: 0.3429\n",
      "Epoch 464/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3162 - val_loss: 0.3429\n",
      "Epoch 465/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3222 - val_loss: 0.3465\n",
      "Epoch 466/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3288 - val_loss: 0.3464\n",
      "Epoch 467/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3173 - val_loss: 0.3437\n",
      "Epoch 468/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - val_loss: 0.3449\n",
      "Epoch 469/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3147 - val_loss: 0.3449\n",
      "Epoch 470/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.3455\n",
      "Epoch 471/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3429\n",
      "Epoch 472/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3182 - val_loss: 0.3429\n",
      "Epoch 473/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3074 - val_loss: 0.3501\n",
      "Epoch 474/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3441\n",
      "Epoch 475/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3096 - val_loss: 0.3453\n",
      "Epoch 476/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3034 - val_loss: 0.3430\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3218 - val_loss: 0.3474\n",
      "Epoch 478/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3259 - val_loss: 0.3474\n",
      "Epoch 479/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3167 - val_loss: 0.3449\n",
      "Epoch 480/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3190 - val_loss: 0.3433\n",
      "Epoch 481/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3148 - val_loss: 0.3447\n",
      "Epoch 482/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.3490\n",
      "Epoch 483/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.3465\n",
      "Epoch 484/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3100 - val_loss: 0.3436\n",
      "Epoch 485/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3152 - val_loss: 0.3452\n",
      "Epoch 486/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3193 - val_loss: 0.3428\n",
      "Epoch 487/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3107 - val_loss: 0.3451\n",
      "Epoch 488/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3140 - val_loss: 0.3463\n",
      "Epoch 489/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.3441\n",
      "Epoch 490/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3155 - val_loss: 0.3472\n",
      "Epoch 491/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.310 - 1s 3ms/step - loss: 0.3109 - val_loss: 0.3525\n",
      "Epoch 492/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3515\n",
      "Epoch 493/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3233 - val_loss: 0.3516\n",
      "Epoch 494/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3201 - val_loss: 0.3439\n",
      "Epoch 495/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3165 - val_loss: 0.3444\n",
      "Epoch 496/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3130 - val_loss: 0.3445\n",
      "Epoch 497/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3505\n",
      "Epoch 498/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3171 - val_loss: 0.3429\n",
      "Epoch 499/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3437\n",
      "Epoch 500/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3274 - val_loss: 0.3491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b991fe28e0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=500,\n",
    "          validation_data=(X_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1593\n",
      "           1       0.67      0.55      0.60       407\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.78      0.74      0.76      2000\n",
      "weighted avg       0.84      0.85      0.85      2000\n",
      "\n",
      "[[1483  110]\n",
      " [ 185  222]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy is coming out to be 0.85**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu'))\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 0.6077 - val_loss: 0.4952\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4960 - val_loss: 0.4681\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4692 - val_loss: 0.4484\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.4341\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4393 - val_loss: 0.4247\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4167\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4198 - val_loss: 0.4115\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.4065\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4009\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.3960\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3949 - val_loss: 0.3934\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.3873\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.3827\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3811 - val_loss: 0.3809\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3769\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.3753\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.3737\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.3736\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.3688\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.3677\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.3699\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.3666\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.3650\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.3651\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.3656\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.3636\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.3637\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.3637\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3630\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3654\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.3634\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.3643\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.3611\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.3646\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.3614\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3511 - val_loss: 0.3607\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.3606\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.3598\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.3604\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.3600\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.3589\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3649 - val_loss: 0.3589\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.3591\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.3606\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3583\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.3608\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3425 - val_loss: 0.3581\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.3589\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3477 - val_loss: 0.3595\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.3590\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.3590\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3592\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.3589\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.3613\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.3633\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.3606\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.3652\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3451 - val_loss: 0.3567\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.3646\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.3567\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - val_loss: 0.3572\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3594\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3560\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3430 - val_loss: 0.3619\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.3560\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3579\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.3596\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.3564\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3570\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3537 - val_loss: 0.3557\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.3556\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3556\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3422 - val_loss: 0.3597\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.3542\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3441 - val_loss: 0.3564\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3560\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3463 - val_loss: 0.3540\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3420 - val_loss: 0.3551\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3366 - val_loss: 0.3548\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3493 - val_loss: 0.3548\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.3538\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3581 - val_loss: 0.3556\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3347 - val_loss: 0.3540\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.3537\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3468 - val_loss: 0.3532\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3525\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3578\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.3534\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3426 - val_loss: 0.3529\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3414 - val_loss: 0.3522\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3272 - val_loss: 0.3539\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 0.3570\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3582\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3403 - val_loss: 0.3611\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3299 - val_loss: 0.3514\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3356 - val_loss: 0.3527\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3382 - val_loss: 0.3539\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.3532\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3354 - val_loss: 0.3540\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3601\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.3508\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.3521\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.3519\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.3600\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3522\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.3509\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3270 - val_loss: 0.3571\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3511\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3367 - val_loss: 0.3523\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.3512\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3544\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3301 - val_loss: 0.3526\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3316 - val_loss: 0.3510\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.3542\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - val_loss: 0.3513\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3430 - val_loss: 0.3505\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3349 - val_loss: 0.3492\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - val_loss: 0.3503\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.3495\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3495\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3508\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3330 - val_loss: 0.3530\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3321 - val_loss: 0.3533\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3386 - val_loss: 0.3507\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3483 - val_loss: 0.3491\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3490\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3313 - val_loss: 0.3505\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3414 - val_loss: 0.3506\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3422 - val_loss: 0.3493\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3460 - val_loss: 0.3487\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3396 - val_loss: 0.3489\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.3489\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.3492\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3318 - val_loss: 0.3495\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.3528\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3414 - val_loss: 0.3507\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3391 - val_loss: 0.3479\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - val_loss: 0.3495\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3532 - val_loss: 0.3554\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3273 - val_loss: 0.3480\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3554\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3269 - val_loss: 0.3510\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3385 - val_loss: 0.3483\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - val_loss: 0.3500\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3348 - val_loss: 0.3499\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3410 - val_loss: 0.3498\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3513\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.3480\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3425 - val_loss: 0.3496\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3512\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3345 - val_loss: 0.3482\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3518\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3505\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3247 - val_loss: 0.3526\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3541\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3315 - val_loss: 0.3484\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3198 - val_loss: 0.3496\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3483\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3275 - val_loss: 0.3493\n",
      "Epoch 160/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - val_loss: 0.3470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3304 - val_loss: 0.3474\n",
      "Epoch 162/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3309 - val_loss: 0.3521\n",
      "Epoch 163/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3489\n",
      "Epoch 164/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3391 - val_loss: 0.3486\n",
      "Epoch 165/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - val_loss: 0.3587\n",
      "Epoch 166/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3317 - val_loss: 0.3474\n",
      "Epoch 167/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3253 - val_loss: 0.3482\n",
      "Epoch 168/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.3554\n",
      "Epoch 169/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3352 - val_loss: 0.3471\n",
      "Epoch 170/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3223 - val_loss: 0.3493\n",
      "Epoch 171/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3283 - val_loss: 0.3574\n",
      "Epoch 172/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3337 - val_loss: 0.3494\n",
      "Epoch 173/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3381 - val_loss: 0.3486\n",
      "Epoch 174/500\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.332 - 1s 3ms/step - loss: 0.3325 - val_loss: 0.3475\n",
      "Epoch 175/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3324 - val_loss: 0.3480\n",
      "Epoch 176/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3310 - val_loss: 0.3482\n",
      "Epoch 177/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3353 - val_loss: 0.3487\n",
      "Epoch 178/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3331 - val_loss: 0.3500\n",
      "Epoch 179/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.3272 - val_loss: 0.3502\n",
      "Epoch 180/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3310 - val_loss: 0.3518\n",
      "Epoch 181/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3327 - val_loss: 0.3515\n",
      "Epoch 182/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3563\n",
      "Epoch 183/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3355 - val_loss: 0.3481\n",
      "Epoch 184/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3344 - val_loss: 0.3486\n",
      "Epoch 185/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - val_loss: 0.3477\n",
      "Epoch 00185: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b994bf6700>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=500,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1593\n",
      "           1       0.71      0.41      0.52       407\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.79      0.68      0.71      2000\n",
      "weighted avg       0.83      0.85      0.83      2000\n",
      "\n",
      "[[1523   70]\n",
      " [ 239  168]]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = model.predict_classes(X_test)\n",
    "print(classification_report(y_test,predictions1))\n",
    "print(confusion_matrix(y_test,predictions1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy is coming out ot be 0.85**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding in DropOut Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=12,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "250/250 [==============================] - 2s 5ms/step - loss: 0.6981 - val_loss: 0.5037\n",
      "Epoch 2/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.5361 - val_loss: 0.4942\n",
      "Epoch 3/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5251 - val_loss: 0.4864\n",
      "Epoch 4/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 0.4758\n",
      "Epoch 5/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - val_loss: 0.4714\n",
      "Epoch 6/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4988 - val_loss: 0.4669\n",
      "Epoch 7/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4936 - val_loss: 0.4643\n",
      "Epoch 8/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4796 - val_loss: 0.4622\n",
      "Epoch 9/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4763 - val_loss: 0.4597\n",
      "Epoch 10/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4796 - val_loss: 0.4571\n",
      "Epoch 11/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4714 - val_loss: 0.4544\n",
      "Epoch 12/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4558 - val_loss: 0.4517\n",
      "Epoch 13/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4676 - val_loss: 0.4505\n",
      "Epoch 14/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4784 - val_loss: 0.4492\n",
      "Epoch 15/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4699 - val_loss: 0.4479\n",
      "Epoch 16/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4634 - val_loss: 0.4463\n",
      "Epoch 17/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4749 - val_loss: 0.4437\n",
      "Epoch 18/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4689 - val_loss: 0.4421\n",
      "Epoch 19/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4608 - val_loss: 0.4455\n",
      "Epoch 20/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4687 - val_loss: 0.4404\n",
      "Epoch 21/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4590 - val_loss: 0.4376\n",
      "Epoch 22/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4573 - val_loss: 0.4371\n",
      "Epoch 23/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4631 - val_loss: 0.4378\n",
      "Epoch 24/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4634 - val_loss: 0.4338\n",
      "Epoch 25/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4553 - val_loss: 0.4312\n",
      "Epoch 26/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4531 - val_loss: 0.4304\n",
      "Epoch 27/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4539 - val_loss: 0.4282\n",
      "Epoch 28/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4418 - val_loss: 0.4243\n",
      "Epoch 29/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4580 - val_loss: 0.4274\n",
      "Epoch 30/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4453 - val_loss: 0.4259\n",
      "Epoch 31/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4520 - val_loss: 0.4237\n",
      "Epoch 32/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4471 - val_loss: 0.4244\n",
      "Epoch 33/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4447 - val_loss: 0.4247\n",
      "Epoch 34/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4469 - val_loss: 0.4225\n",
      "Epoch 35/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4537 - val_loss: 0.4215\n",
      "Epoch 36/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4474 - val_loss: 0.4211\n",
      "Epoch 37/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4555 - val_loss: 0.4199\n",
      "Epoch 38/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4571 - val_loss: 0.4180\n",
      "Epoch 39/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4495 - val_loss: 0.4188\n",
      "Epoch 40/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4428 - val_loss: 0.4186\n",
      "Epoch 41/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4514 - val_loss: 0.4170\n",
      "Epoch 42/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4513 - val_loss: 0.4180\n",
      "Epoch 43/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4553 - val_loss: 0.4150\n",
      "Epoch 44/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4451 - val_loss: 0.4170\n",
      "Epoch 45/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4430 - val_loss: 0.4187\n",
      "Epoch 46/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4149\n",
      "Epoch 47/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4445 - val_loss: 0.4154\n",
      "Epoch 48/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4399 - val_loss: 0.4168\n",
      "Epoch 49/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.4169\n",
      "Epoch 50/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4333 - val_loss: 0.4150\n",
      "Epoch 51/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4563 - val_loss: 0.4151\n",
      "Epoch 52/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4518 - val_loss: 0.4152\n",
      "Epoch 53/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4409 - val_loss: 0.4173\n",
      "Epoch 54/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4401 - val_loss: 0.4152\n",
      "Epoch 55/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4427 - val_loss: 0.4153\n",
      "Epoch 56/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4361 - val_loss: 0.4127\n",
      "Epoch 57/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4441 - val_loss: 0.4129\n",
      "Epoch 58/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4400 - val_loss: 0.4126\n",
      "Epoch 59/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4396 - val_loss: 0.4104\n",
      "Epoch 60/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4334 - val_loss: 0.4106\n",
      "Epoch 61/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4317 - val_loss: 0.4093\n",
      "Epoch 62/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4313 - val_loss: 0.4106\n",
      "Epoch 63/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4523 - val_loss: 0.4098\n",
      "Epoch 64/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4350 - val_loss: 0.4104\n",
      "Epoch 65/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4359 - val_loss: 0.4122\n",
      "Epoch 66/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4365 - val_loss: 0.4066\n",
      "Epoch 67/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4454 - val_loss: 0.4113\n",
      "Epoch 68/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.4094\n",
      "Epoch 69/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4477 - val_loss: 0.4098\n",
      "Epoch 70/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4437 - val_loss: 0.4098\n",
      "Epoch 71/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4294 - val_loss: 0.4098\n",
      "Epoch 72/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4378 - val_loss: 0.4085\n",
      "Epoch 73/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4254 - val_loss: 0.4080\n",
      "Epoch 74/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.4092\n",
      "Epoch 75/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4408 - val_loss: 0.4103\n",
      "Epoch 76/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4340 - val_loss: 0.4089\n",
      "Epoch 77/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4266 - val_loss: 0.4103\n",
      "Epoch 78/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4376 - val_loss: 0.4066\n",
      "Epoch 79/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4307 - val_loss: 0.4090\n",
      "Epoch 80/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4233 - val_loss: 0.4089\n",
      "Epoch 81/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4356 - val_loss: 0.4089\n",
      "Epoch 82/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4312 - val_loss: 0.4069\n",
      "Epoch 83/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4310 - val_loss: 0.4087\n",
      "Epoch 84/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4297 - val_loss: 0.4060\n",
      "Epoch 85/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4424 - val_loss: 0.4071\n",
      "Epoch 86/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4384 - val_loss: 0.4075\n",
      "Epoch 87/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4366 - val_loss: 0.4076\n",
      "Epoch 88/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4363 - val_loss: 0.4076\n",
      "Epoch 89/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.4063\n",
      "Epoch 90/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4366 - val_loss: 0.4102\n",
      "Epoch 91/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4434 - val_loss: 0.4055\n",
      "Epoch 92/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4051\n",
      "Epoch 93/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4419 - val_loss: 0.4107\n",
      "Epoch 94/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4057\n",
      "Epoch 95/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4258 - val_loss: 0.4069\n",
      "Epoch 96/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4403 - val_loss: 0.4055\n",
      "Epoch 97/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4368 - val_loss: 0.4056\n",
      "Epoch 98/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4289 - val_loss: 0.4083\n",
      "Epoch 99/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4513 - val_loss: 0.4049\n",
      "Epoch 100/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4439 - val_loss: 0.4048\n",
      "Epoch 101/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4232 - val_loss: 0.4084\n",
      "Epoch 102/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4338 - val_loss: 0.4063\n",
      "Epoch 103/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4392 - val_loss: 0.4088\n",
      "Epoch 104/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4361 - val_loss: 0.4065\n",
      "Epoch 105/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4327 - val_loss: 0.4076\n",
      "Epoch 106/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4420 - val_loss: 0.4059\n",
      "Epoch 107/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4485 - val_loss: 0.4097\n",
      "Epoch 108/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4272 - val_loss: 0.4049\n",
      "Epoch 109/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.4060\n",
      "Epoch 110/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4306 - val_loss: 0.4099\n",
      "Epoch 111/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4335 - val_loss: 0.4076\n",
      "Epoch 112/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4351 - val_loss: 0.4076\n",
      "Epoch 113/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4294 - val_loss: 0.4047\n",
      "Epoch 114/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4066\n",
      "Epoch 115/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4259 - val_loss: 0.4053\n",
      "Epoch 116/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4435 - val_loss: 0.4040\n",
      "Epoch 117/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4323 - val_loss: 0.4065\n",
      "Epoch 118/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4341 - val_loss: 0.4042\n",
      "Epoch 119/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4288 - val_loss: 0.4077\n",
      "Epoch 120/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4421 - val_loss: 0.4070\n",
      "Epoch 121/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4397 - val_loss: 0.4032\n",
      "Epoch 122/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4449 - val_loss: 0.4075\n",
      "Epoch 123/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4286 - val_loss: 0.4063\n",
      "Epoch 124/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4315 - val_loss: 0.4060\n",
      "Epoch 125/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4483 - val_loss: 0.4074\n",
      "Epoch 126/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4412 - val_loss: 0.4058\n",
      "Epoch 127/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4332 - val_loss: 0.4053\n",
      "Epoch 128/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4270 - val_loss: 0.4069\n",
      "Epoch 129/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4234 - val_loss: 0.4076\n",
      "Epoch 130/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4439 - val_loss: 0.4041\n",
      "Epoch 131/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4056\n",
      "Epoch 132/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4288 - val_loss: 0.4021\n",
      "Epoch 133/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4293 - val_loss: 0.4054\n",
      "Epoch 134/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4243 - val_loss: 0.4058\n",
      "Epoch 135/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4370 - val_loss: 0.4053\n",
      "Epoch 136/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4358 - val_loss: 0.4014\n",
      "Epoch 137/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.4053\n",
      "Epoch 138/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 139/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4305 - val_loss: 0.4034\n",
      "Epoch 140/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4459 - val_loss: 0.4066\n",
      "Epoch 141/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4343 - val_loss: 0.4055\n",
      "Epoch 142/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4303 - val_loss: 0.4049\n",
      "Epoch 143/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.4030\n",
      "Epoch 144/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4063\n",
      "Epoch 145/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4052\n",
      "Epoch 146/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4417 - val_loss: 0.4046\n",
      "Epoch 147/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4414 - val_loss: 0.4057\n",
      "Epoch 148/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4255 - val_loss: 0.4029\n",
      "Epoch 149/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4389 - val_loss: 0.4053\n",
      "Epoch 150/500\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.4475 - val_loss: 0.4059\n",
      "Epoch 151/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4426 - val_loss: 0.4026\n",
      "Epoch 152/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4318 - val_loss: 0.4056\n",
      "Epoch 153/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4232 - val_loss: 0.4060\n",
      "Epoch 154/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4342 - val_loss: 0.4037\n",
      "Epoch 155/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4031\n",
      "Epoch 156/500\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.4308 - val_loss: 0.4056\n",
      "Epoch 157/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4314 - val_loss: 0.4070\n",
      "Epoch 158/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4319 - val_loss: 0.4060\n",
      "Epoch 159/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4282 - val_loss: 0.4062\n",
      "Epoch 160/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4428 - val_loss: 0.4042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "250/250 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4050\n",
      "Epoch 00161: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b99501c160>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=500,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90      1593\n",
      "           1       0.95      0.14      0.25       407\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.89      0.57      0.57      2000\n",
      "weighted avg       0.85      0.82      0.77      2000\n",
      "\n",
      "[[1590    3]\n",
      " [ 349   58]]\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model.predict_classes(X_test)\n",
    "print(classification_report(y_test,predictions2))\n",
    "print(confusion_matrix(y_test,predictions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The accuracy is coming out ot be 0.82**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geography: France\n",
    "\n",
    "Credit Score: 499\n",
    "\n",
    "Gender: Male\n",
    "\n",
    "Age: 39 years old\n",
    "\n",
    "Tenure: 3 years\n",
    "\n",
    "Balance: $50000\n",
    "\n",
    "Number of Products: 2\n",
    "\n",
    "Does this customer have a credit card ? Yes\n",
    "\n",
    "Is this customer an Active Member: Yes\n",
    "\n",
    "Estimated Salary: $60000**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew=scaler.transform([[499,0,1,39,3,50000,2,1,1,60000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaibhav\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict_classes(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**According to model's prediction, The customer will not exit**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
